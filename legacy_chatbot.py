import streamlit as st
from supabase import create_client
import requests
import re
import pandas as pd
import json

# -------------------------------------------------------------------------
# 1. ì„¤ì • ë° ì´ˆê¸°í™”
# -------------------------------------------------------------------------

# Supabase ì„¤ì • (secrets ìš°ì„ )
SUPABASE_URL = st.secrets.get("SUPABASE_URL", "https://qipphcdzlmqidhrjnjtt.supabase.co")
SUPABASE_KEY = st.secrets.get("SUPABASE_KEY", "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InFpcHBoY2R6bG1xaWRocmpuanR0Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3NjY5NTIwMTIsImV4cCI6MjA4MjUyODAxMn0.AsuvjVGCLUJF_IPvQevYASaM6uRF2C6F-CjwC3eCNVk")

# Gemini API Key (secretsì—ì„œ ì½ê¸°)
GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY", "AIzaSyAQaiwm46yOITEttdr0ify7duXCW3TwGRo")


@st.cache_resource
def init_supabase():
    return create_client(SUPABASE_URL, SUPABASE_KEY)


supabase = init_supabase()

# -------------------------------------------------------------------------
# 2. íŒŒì‹± ë° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# -------------------------------------------------------------------------

def extract_date_info(text):
    """ì§ˆë¬¸ì—ì„œ ë‚ ì§œ(YYYY-MM-DD)ì™€ ì›”(MM) ì •ë³´ë¥¼ ì¶”ì¶œ"""
    info = {"date": None, "month": None, "year": "2025"}

    match_date = re.search(r"(\d{1,2})ì›”\s*(\d{1,2})ì¼", text)
    if match_date:
        m, d = match_date.groups()
        info["month"] = int(m)
        info["date"] = f"{info['year']}-{int(m):02d}-{int(d):02d}"
    else:
        match_month = re.search(r"(\d{1,2})ì›”", text)
        if match_month:
            info["month"] = int(match_month.group(1))

    return info


def extract_version(text):
    if "0ì°¨" in text or "ì´ˆê¸°" in text or "ê³„íš" in text:
        return "0ì°¨"
    return "ìµœì¢…"


def extract_product_keyword(text):
    ignore_words = [
        "ìƒì‚°ëŸ‰", "ì•Œë ¤ì¤˜", "ë¹„êµí•´ì¤˜", "ë¹„êµ", "ì œí’ˆ", "ìµœì¢…", "0ì°¨", "ì›”", "ì¼", "capa", "ì¹´íŒŒ",
        "ì´ˆê³¼", "ì–´ë–»ê²Œ", "ë¼", "ìˆì–´", "ì‚¬ë¡€", "ì´", "fan", "motor", "flange", "íŒ¬", "ëª¨í„°", "í”Œëœì§€"
    ]
    words = text.split()
    for w in words:
        clean_w = re.sub(r"[^a-zA-Z0-9ê°€-í£]", "", w)
        if clean_w and clean_w.lower() not in ignore_words and not re.match(r"\d+(ì›”|ì¼)", clean_w):
            return clean_w
    return None


def normalize_line_name(line_val):
    """
    daily_capaì˜ '1','2','3' (int/str) -> 'ì¡°ë¦½1','ì¡°ë¦½2','ì¡°ë¦½3'
    daily_total_productionì˜ 'ì¡°ë¦½1' -> 'ì¡°ë¦½1' (ìœ ì§€)
    """
    s = str(line_val).strip()
    if s == '1':
        return 'ì¡°ë¦½1'
    if s == '2':
        return 'ì¡°ë¦½2'
    if s == '3':
        return 'ì¡°ë¦½3'
    if 'ì¡°ë¦½' in s:
        return s
    return s


def normalize_date(date_val):
    """
    ë‚ ì§œ ë¬¸ìì—´ì—ì„œ ì‹œê°„ ë¶€ë¶„ì„ ì œê±°í•˜ê³  YYYY-MM-DD í˜•ì‹ë§Œ ë‚¨ê¹€
    ì˜ˆ: 2025-09-05T00:00:00 -> 2025-09-05
    """
    if not date_val:
        return ""
    s = str(date_val).strip()
    if len(s) >= 10:
        return s[:10]
    return s


# -------------------------------------------------------------------------
# 3. ë°ì´í„° ì¡°íšŒ ë¡œì§
# -------------------------------------------------------------------------

def fetch_db_data(user_input):
    info = extract_date_info(user_input)
    target_date = info["date"]
    target_month = info["month"]
    target_version = extract_version(user_input)
    product_key = extract_product_keyword(user_input)

    context_log = ""

    try:
        # =================================================================
        # 1. ê³¼ê±° ì´ìŠˆ ì‚¬ë¡€ ê²€ìƒ‰ (MDL1 ~ CCL)
        # =================================================================
        if "ì‚¬ë¡€" in user_input:
            issue_mapping = {
                "MDL1": {"keywords": ["ë¨¼ì €", "ì¤„ì—¬", "ìˆœìœ„", "êµì²´"], "db_text": "ìƒì‚°ìˆœìœ„ ì¡°ì •", "title": "MDL1: ë¯¸ë‹¬(ìƒì‚°ìˆœìœ„ ì¡°ì •/ëª¨ë¸ êµì²´)"},
                "MDL2": {"keywords": ["ê°ì‚¬", "ì •ì§€", "ì„¤ë¹„", "ë¼ì¸ì „ì²´"], "db_text": "ë¼ì¸ì „ì²´ì´ìŠˆ", "title": "MDL2: ë¯¸ë‹¬(ë¼ì¸ì „ì²´ì´ìŠˆ/ì„¤ë¹„)"},
                "MDL3": {"keywords": ["ë¶€í’ˆ", "ìì¬", "ê²°í’ˆ", "ìˆ˜ê¸‰", "ì•ˆë˜ëŠ”"], "db_text": "ìì¬ê²°í’ˆ", "title": "MDL3: ë¯¸ë‹¬(ë¶€í’ˆìˆ˜ê¸‰/ìì¬ê²°í’ˆ)"},
                "PRP": {"keywords": ["ì„ í–‰", "ë¯¸ë¦¬", "ë‹¹ê²¨", "ë•¡ê²¨"], "db_text": "ì„ í–‰ ìƒì‚°", "title": "PRP: ì„ í–‰ ìƒì‚°(ìˆ™ì œ ë¯¸ë¦¬í•˜ê¸°)"},
                "SMP": {"keywords": ["ìƒ˜í”Œ", "ê¸´ê¸‰"], "db_text": "ê³„íšì™¸ ê¸´ê¸‰ ìƒì‚°", "title": "SMP: ê³„íšì™¸ ê¸´ê¸‰ ìƒì‚°"},
                "CCL": {"keywords": ["ì·¨ì†Œ"], "db_text": "ê³„íš ì·¨ì†Œ", "title": "CCL: ê³„íš ì·¨ì†Œ/ë¼ì¸ ê°€ë™ì¤‘ë‹¨"}
            }

            detected_code = None
            for code, meta in issue_mapping.items():
                if any(k in user_input for k in meta["keywords"]):
                    detected_code = code
                    break

            if detected_code:
                meta = issue_mapping[detected_code]
                query = supabase.table("production_issue_analysis_8_11").select("í’ˆëª©ëª…, ë‚ ì§œ, ê³„íš_v0, ì‹¤ì _v2, ëˆ„ì ì°¨ì´_Gap, ìµœì¢…_ì´ìŠˆë¶„ë¥˜")

                if detected_code == "MDL2":
                    query = query.or_(f"ìµœì¢…_ì´ìŠˆë¶„ë¥˜.ilike.%ë¼ì¸ì „ì²´ì´ìŠˆ%,ìµœì¢…_ì´ìŠˆë¶„ë¥˜.ilike.%ì„¤ë¹„%")
                elif detected_code == "MDL3":
                    query = query.or_(f"ìµœì¢…_ì´ìŠˆë¶„ë¥˜.ilike.%ë¶€í’ˆìˆ˜ê¸‰%,ìµœì¢…_ì´ìŠˆë¶„ë¥˜.ilike.%ìì¬ê²°í’ˆ%")
                else:
                    query = query.ilike("ìµœì¢…_ì´ìŠˆë¶„ë¥˜", f"%{meta['db_text']}%")

                response = query.limit(3).execute()

                if response.data:
                    context_log += f"[{detected_code} CASE FOUND]\n"
                    context_log += f"Title: {meta['title']}\n"
                    context_log += f"Data: {json.dumps(response.data, ensure_ascii=False)}"
                    return context_log
                else:
                    return "ê´€ë ¨ëœ ê³¼ê±° ìœ ì‚¬ ì‚¬ë¡€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # =================================================================
        # 2. ì›”ê°„ ìƒì‚°ëŸ‰ ë¸Œë¦¬í•‘
        # =================================================================
        found_months = re.findall(r"(\d{1,2})ì›”", user_input)
        found_months = sorted(list(set([int(m) for m in found_months])))

        if len(found_months) >= 2 and product_key is None:
            target_ver = extract_version(user_input)
            res = supabase.table("monthly_production").select("ì›”, ì´_ìƒì‚°ëŸ‰").in_("ì›”", found_months).eq("ë²„ì „", target_ver).execute()

            if res.data:
                df = pd.DataFrame(res.data)
                df = df.sort_values(by='ì›”')
                context_log += f"\n[{target_ver} ì›”ê°„ ì´ ìƒì‚°ëŸ‰ ë¸Œë¦¬í•‘]\n"
                prev_val = None
                prev_month = None
                for _, row in df.iterrows():
                    m = row['ì›”']
                    val = row['ì´_ìƒì‚°ëŸ‰']
                    msg = f"{m}ì›”: {val:,}"
                    if prev_val is not None:
                        diff = val - prev_val
                        if diff > 0:
                            msg += f" (ì „ì›”({prev_month}ì›”) ëŒ€ë¹„ {diff:,} ì¦ê°€ ğŸ”º)"
                        elif diff < 0:
                            msg += f" (ì „ì›”({prev_month}ì›”) ëŒ€ë¹„ {abs(diff):,} ê°ì†Œ ğŸ”»)"
                        else:
                            msg += " (ë³€ë™ ì—†ìŒ)"
                    context_log += f"- {msg}\n"
                    prev_val = val
                    prev_month = m
                return context_log
            else:
                return "ìš”ì²­í•˜ì‹  ì›”ì˜ ë°ì´í„°ê°€ monthly_production í…Œì´ë¸”ì— ì—†ìŠµë‹ˆë‹¤."

        # =================================================================
        # 3. ë‹¨ìˆœ CAPA ì¡°íšŒ ("00ì›” CAPA ì•Œë ¤ì¤˜")
        # =================================================================
        if target_month and ("capa" in user_input.lower() or "ì¹´íŒŒ" in user_input) and "ë¹„êµ" not in user_input and "ì´ˆê³¼" not in user_input and not target_date:
            res_capa = supabase.table("daily_capa").select("ë¼ì¸, capa").eq("ì›”", target_month).eq("ë²„ì „", target_version).execute()
            if res_capa.data:
                df = pd.DataFrame(res_capa.data)
                df['ë¼ì¸'] = df['ë¼ì¸'].apply(normalize_line_name)
                display_data = {}
                grouped = df.groupby('ë¼ì¸')['capa'].apply(list).to_dict()
                for line, capas in grouped.items():
                    unique_capas = sorted(list(set(capas)))
                    display_data[line] = unique_capas[0] if len(unique_capas) == 1 else unique_capas
                context_log += f"\n[{target_month}ì›” {target_version} ë¼ì¸ë³„ CAPA ì •ë³´ (ì»¬ëŸ¼ê°’)]: {display_data}"
                return context_log
            else:
                context_log += f"\n[{target_month}ì›” {target_version} CAPA ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.]"
                return context_log

        # =================================================================
        # 4. CAPA ì´ˆê³¼ / ë¹„êµ ë¡œì§
        # =================================================================
        if ("ë¹„êµ" in user_input and "ì›”" in user_input and product_key is None) or ("ì´ˆê³¼" in user_input and "ì›”" in user_input):
            res_capa = supabase.table("daily_capa").select("*").eq("ì›”", target_month).eq("ë²„ì „", "ìµœì¢…").execute()
            res_prod = supabase.table("daily_total_production").select("*").eq("ì›”", target_month).eq("ë²„ì „", "ìµœì¢…").execute()

            if not res_capa.data or not res_prod.data:
                context_log += f"\n[ì•Œë¦¼] ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨. Capa ë°ì´í„°: {len(res_capa.data) if res_capa.data else 0}ê±´, Prod ë°ì´í„°: {len(res_prod.data) if res_prod.data else 0}ê±´"
                return context_log

            capa_reference = {}
            for item in res_capa.data:
                line_key = normalize_line_name(item['ë¼ì¸'])
                capa_reference[line_key] = item['capa']

            over_list = []
            for row in res_prod.data:
                p_date = normalize_date(row['ë‚ ì§œ'])
                p_line = normalize_line_name(row['ë¼ì¸'])
                p_qty = row['ì´_ìƒì‚°ëŸ‰']

                limit = capa_reference.get(p_line, 0)

                if limit > 0 and p_qty > limit:
                    over_list.append(f"| {p_date} | {p_line} | {limit} | {p_qty} |")

            if "ì´ˆê³¼" in user_input:
                if over_list:
                    over_list.sort()
                    context_log += f"\n[CAPA ì´ˆê³¼ ë¦¬ìŠ¤íŠ¸ (í˜•ì‹: ë‚ ì§œ|ë¼ì¸|CAPA|ì´ ìƒì‚°ëŸ‰)]:\n"
                    for item in over_list:
                        context_log += f"{item}\n"
                else:
                    context_log += f"\n[ì•Œë¦¼] {target_month}ì›” ì‹¤ì  ë°ì´í„°ë¥¼ ê²€í† í–ˆìœ¼ë‚˜, ì„¤ì •ëœ CAPAë¥¼ ì´ˆê³¼í•œ ë‚ ì´ ì—†ìŠµë‹ˆë‹¤."
            else:
                context_log += f"\n[ì•Œë¦¼] {target_month}ì›” ë°ì´í„° ë¹„êµ ì™„ë£Œ. (ì´ ì‹¤ì  ë°ì´í„° {len(res_prod.data)}ê±´ ê²€í† ë¨)"

            return context_log

        # =================================================================
        # 5. ê¸°íƒ€ ì¡°íšŒ
        # =================================================================
        gubun_keywords = ["fan", "motor", "flange", "íŒ¬", "ëª¨í„°", "í”Œëœì§€"]
        if target_month and any(k in user_input.lower() for k in gubun_keywords):
            if "fan" in user_input.lower() or "íŒ¬" in user_input:
                target_gubun = "Fan"
            elif "motor" in user_input.lower() or "ëª¨í„°" in user_input:
                target_gubun = "Motor"
            else:
                target_gubun = "Flange"

            query = supabase.table("production_data").select("ìƒì‚°ëŸ‰") \
                .eq("ì›”", target_month) \
                .eq("ë²„ì „", "ìµœì¢…") \
                .ilike("êµ¬ë¶„", f"%{target_gubun}%")
            res = query.execute()
            if res.data:
                total_qty = sum([item['ìƒì‚°ëŸ‰'] for item in res.data])
                context_log += f"\n[{target_month}ì›” {target_gubun} (ìµœì¢…) ì´ ìƒì‚°ëŸ‰]: {total_qty:,} (ë°ì´í„° {len(res.data)}ê±´ í•©ê³„)"
            else:
                context_log += f"\n[{target_month}ì›” {target_gubun} ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.]"
            return context_log

        if target_date and product_key:
            query_prod = supabase.table("production_data").select("*")
            query_prod = query_prod.ilike("í’ˆëª…", f"%{product_key}%")

            if "ë¹„êµ" in user_input:
                res_v0 = supabase.table("production_data").select("*").eq("ë‚©ê¸°ì¼", target_date).eq("ë²„ì „", "0ì°¨").ilike("í’ˆëª…", f"%{product_key}%").execute()
                res_final = supabase.table("production_data").select("*").eq("ìƒì‚°ì¼", target_date).eq("ë²„ì „", "ìµœì¢…").ilike("í’ˆëª…", f"%{product_key}%").execute()
                v0_qty = sum([x['ìƒì‚°ëŸ‰'] for x in res_v0.data]) if res_v0.data else 0
                final_qty = sum([x['ìƒì‚°ëŸ‰'] for x in res_final.data]) if res_final.data else 0
                context_log += f"\n[ë¹„êµ ê²°ê³¼ ({target_date} {product_key})]\n"
                context_log += f"- 0ì°¨(ë‚©ê¸°ì¼ ê¸°ì¤€): {v0_qty}\n"
                context_log += f"- ìµœì¢…(ìƒì‚°ì¼ ê¸°ì¤€): {final_qty}\n"
            else:
                ver_col = "ë‚©ê¸°ì¼" if target_version == "0ì°¨" else "ìƒì‚°ì¼"
                query_prod = query_prod.eq("ë²„ì „", target_version).eq(ver_col, target_date)
                res_prod = query_prod.execute()
                if res_prod.data:
                    context_log += f"\n[ì œí’ˆ ë°ì´í„° ({target_version})]: {res_prod.data}"
                    total_p = sum([x.get('ìƒì‚°ëŸ‰', 0) for x in res_prod.data])
                    context_log += f"\n[ì´ ìƒì‚°ëŸ‰]: {total_p}"
                else:
                    context_log += f"\n[ì•Œë¦¼] '{target_date}'ì— '{product_key}' ì œí’ˆì˜ {target_version} ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
            return context_log

        if target_date and "ìƒì‚°ëŸ‰" in user_input:
            res = supabase.table("daily_total_production").select("ì´_ìƒì‚°ëŸ‰").eq("ë‚ ì§œ", target_date).eq("ë²„ì „", target_version).execute()
            if res.data:
                total_qty = sum([item['ì´_ìƒì‚°ëŸ‰'] for item in res.data])
                context_log += f"\n[{target_date} {target_version} ì´ ìƒì‚°ëŸ‰]: {total_qty:,} (daily_total í•©ê³„)"
            else:
                ver_col = "ë‚©ê¸°ì¼" if target_version == "0ì°¨" else "ìƒì‚°ì¼"
                res_fallback = supabase.table("production_data").select("ìƒì‚°ëŸ‰").eq(ver_col, target_date).eq("ë²„ì „", target_version).execute()
                if res_fallback.data:
                    total = sum([x['ìƒì‚°ëŸ‰'] for x in res_fallback.data])
                    context_log += f"\n[{target_date} {target_version} ì´ ìƒì‚°ëŸ‰ (Item ì§‘ê³„)]: {total:,}"
                else:
                    context_log += f"\n[{target_date} ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.]"
            return context_log

        if target_date and ("capa" in user_input.lower() or "ì¹´íŒŒ" in user_input):
            res = supabase.table("daily_capa").select("*").eq("ë‚ ì§œ", target_date).eq("ë²„ì „", target_version).execute()
            if res.data:
                context_log += f"\n[{target_date} {target_version} CAPA ì •ë³´]: {res.data}"
            else:
                context_log += f"\n[{target_date} CAPA ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.]"
            return context_log

    except Exception as e:
        return f"ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

    if not context_log:
        return "ìš”ì²­í•˜ì‹  ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    return context_log


# -------------------------------------------------------------------------
# 4. LLM ì‘ë‹µ ìƒì„± (Gemini 2.0 Flash Experimental ì ìš©)
# -------------------------------------------------------------------------

def query_gemini_ai(user_input, context):
    system_prompt = f"""
ë‹¹ì‹ ì€ ìˆ™ë ¨ëœ ìƒì‚°ê³„íš ë‹´ë‹¹ìì…ë‹ˆë‹¤. ì œê³µëœ ë°ì´í„°(Context)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.

[ì¤‘ìš”: CAPA ì´ˆê³¼ ë‹µë³€ ê·œì¹™]
Contextì— '[CAPA ì´ˆê³¼ ë¦¬ìŠ¤íŠ¸]'ê°€ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´, ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ì˜ ë§ˆí¬ë‹¤ìš´ í‘œ(Table)ë¡œ ì¶œë ¥í•˜ì„¸ìš”.
(Contextì— ìˆëŠ” ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.)

| ë‚ ì§œ | ë¼ì¸ | CAPA | ì´ ìƒì‚°ëŸ‰ |
|---|---|---|---|
| ... | ... | ... | ... |

[ì¤‘ìš”: ì´ìŠˆ ì½”ë“œ ë‹µë³€ ê·œì¹™]
Contextì— [CODE CASE FOUND]ê°€ ìˆë‹¤ë©´:
1. ë‹µë³€ ìµœìƒë‹¨ì— ì½”ë“œëª…ê³¼ ì œëª©ì„ # Heading 1ë¡œ ì ìœ¼ì„¸ìš”.
2. ë°ì´í„°(Data)ë¥¼ ë°”íƒ•ìœ¼ë¡œ í‘œë¥¼ ì‘ì„±í•˜ì„¸ìš”: [ë‚ ì§œ | í’ˆëª©ëª… | ê³„íš(V0) | ì‹¤ì (V2) | ì°¨ì´(Gap)]

[ì¼ë°˜ ë‹µë³€ ê·œì¹™]
1. ìˆ«ìëŠ” ì œê³µëœ ê·¸ëŒ€ë¡œ ì „ë‹¬í•˜ì„¸ìš”.
2. ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì—†ë‹¤ê³  í•˜ì„¸ìš”.
3. CAPA ì´ˆê³¼ ì§ˆë¬¸ ì‹œ, ì´ˆê³¼ ë¦¬ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ í‘œë¥¼ ë³´ì—¬ì£¼ê³ , ì—†ìœ¼ë©´ ì—†ë‹¤ê³  ëª…í™•íˆ ë§í•˜ì„¸ìš”.

[Context Data]:
{context}

[User Question]:
{user_input}
"""

    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?key={GEMINI_API_KEY}"
    headers = {"Content-Type": "application/json"}
    data = {"contents": [{"parts": [{"text": system_prompt}]}]}

    try:
        response = requests.post(url, headers=headers, json=data, timeout=60)
        if response.status_code == 200:
            result = response.json()
            try:
                return result['candidates'][0]['content']['parts'][0]['text']
            except Exception:
                return "ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨"
        else:
            return f"API ì˜¤ë¥˜: {response.status_code}"
    except Exception as e:
        return f"í†µì‹  ì˜¤ë¥˜: {e}"


# -------------------------------------------------------------------------
# 5. UI (íƒ­ì—ì„œ í˜¸ì¶œ)
# -------------------------------------------------------------------------

def render_legacy_chatbot():
    st.subheader("ğŸ­ ìƒì‚°ê³„íš ë³´ì¡° ì±—ë´‡")
    st.caption("ì˜ˆ: 9ì›” 5ì¼ ìµœì¢… ìƒì‚°ëŸ‰ ì•Œë ¤ì¤˜ / 10ì›” CAPA ì´ˆê³¼í•œ ë‚  ìˆì–´? / 9ì›” 10ì›” ìµœì¢… ì´ ìƒì‚°ëŸ‰ ë¸Œë¦¬í•‘")

    if "legacy_messages" not in st.session_state:
        st.session_state.legacy_messages = []

    for message in st.session_state.legacy_messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input(
        "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 9ì›” 5ì¼ ìµœì¢… ìƒì‚°ëŸ‰ ì•Œë ¤ì¤˜, 10ì›” CAPA ì´ˆê³¼í•œ ë‚  ìˆì–´?)",
        key="legacy_input"
    ):
        st.session_state.legacy_messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("ë°ì´í„° ë¶„ì„ ì¤‘..."):
                db_result = fetch_db_data(prompt)
                if "ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in db_result or "ì˜¤ë¥˜" in db_result:
                    final_response = db_result
                else:
                    final_response = query_gemini_ai(prompt, db_result)
                st.markdown(final_response)

        st.session_state.legacy_messages.append({"role": "assistant", "content": final_response})
